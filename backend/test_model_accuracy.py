#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de test d'accuracy pour le modÃ¨le de dÃ©tection d'intention du chatbot
Avec barres de progression vertes pour la visualisation
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), 'app'))

from app.main import detect_intent, create_progress_bar
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import pandas as pd

# Jeu de donnÃ©es de test avec exemples et leurs intentions attendues
TEST_DATA = [
    # Salutations
    ("bonjour", "greeting"),
    ("salut", "greeting"),
    ("hello", "greeting"),
    ("coucou", "greeting"),
    ("bjr", "greeting"),
    ("hi", "greeting"),
    
    # Politesse
    ("merci", "politeness"),
    ("thank you", "politeness"),
    ("thanks", "politeness"),
    ("mrc", "politeness"),
    
    # Questions sur le rÃ´le
    ("quel est ton rÃ´le", "role_query"),
    ("qui es-tu", "role_query"),
    ("tu fais quoi", "role_query"),
    ("ta mission", "role_query"),
    ("t qui", "role_query"),
    
    # Questions sur l'Ã©tat
    ("comment Ã§a va", "status_query"),
    ("Ã§a va", "status_query"),
    ("comment vas-tu", "status_query"),
    ("cava", "status_query"),
    ("cv", "status_query"),
    ("comment allez vous", "status_query"),
    
    # Historique/logs
    ("mes logs", "chat_history"),
    ("historique de chat", "chat_history"),
    ("affiche mes logs", "chat_history"),
    
    # Liste des congÃ©s RH
    ("liste des congÃ©s", "liste_conges_rh"),
    ("demandes de congÃ©", "liste_conges_rh"),
    ("historique des congÃ©s", "liste_conges_rh"),
    ("suivi des congÃ©s", "liste_conges_rh"),
    
    # Suivi personnel des congÃ©s
    ("mes congÃ©s", "suivi_mes_conges"),
    ("suivi de mes congÃ©s", "suivi_mes_conges"),
    ("mes demandes de congÃ©", "suivi_mes_conges"),
    ("statut de ma demande", "suivi_mes_conges"),
    ("ma derniÃ¨re demande", "suivi_mes_conges"),
    
    # Demandes de congÃ©
    ("je veux poser un congÃ©", "demande_conge"),
    ("demande de congÃ©", "demande_conge"),
    ("vacances", "demande_conge"),
    ("absence", "demande_conge"),
    ("congÃ©", "demande_conge"),
    
    # Explication pourcentage
    ("pourquoi ce pourcentage", "explain_percentage"),
    ("dÃ©tail du calcul", "explain_percentage"),
    ("explication du pourcentage", "explain_percentage"),
    ("comment ce pourcentage", "explain_percentage"),
    
    # ProcÃ©dures congÃ©
    ("procedure pour les congÃ©s", "procedure_conge"),
    ("comment poser un congÃ©", "procedure_conge"),
    ("delai congÃ©", "procedure_conge"),
    ("documents congÃ©", "procedure_conge"),
    ("procedure congÃ©", "procedure_conge"),
    ("comment faire une demande", "procedure_conge"),
    ("Ã©tapes pour congÃ©", "procedure_conge"),
    ("marche Ã  suivre", "procedure_conge"),
    
    # PrÃ©vision charge
    ("prÃ©vision charge", "workload_forecast"),
    ("charge de travail", "workload_forecast"),
    ("analyse charge", "workload_forecast"),
    ("missions en cours", "workload_forecast"),
    
    # Messages sans intention claire (doivent retourner None)
    ("test", None),
    ("abc", None),
    ("1234", None),
    ("", None),
    ("blablabla", None),
]

def test_model_accuracy():
    """
    Teste l'accuracy du modÃ¨le de dÃ©tection d'intention
    """
    print("ğŸ§ª DÃ‰MARRAGE DU TEST D'ACCURACY DU MODÃˆLE")
    print("=" * 60)
    
    # Extraire les inputs et les labels attendus
    test_inputs = [data[0] for data in TEST_DATA]
    expected_labels = [data[1] for data in TEST_DATA]
    
    # Faire les prÃ©dictions
    print("ğŸ“Š PrÃ©diction en cours...")
    predicted_labels = []
    
    for i, input_text in enumerate(test_inputs):
        try:
            prediction = detect_intent(input_text)
            predicted_labels.append(prediction)
            print(f"âœ“ {i+1:2d}/{len(test_inputs)} - '{input_text}' -> {prediction}")
        except Exception as e:
            print(f"âŒ Erreur sur '{input_text}': {e}")
            predicted_labels.append(None)
    
    print("\n" + "=" * 60)
    
    # Calculer l'accuracy avec barre verte
    correct_predictions = sum(1 for pred, true in zip(predicted_labels, expected_labels) if pred == true)
    total_predictions = len(expected_labels)
    accuracy = correct_predictions / total_predictions
    accuracy_percentage = accuracy * 100
    
    print(f"ğŸ“ˆ RÃ‰SULTATS D'ACCURACY:")
    print(f"   PrÃ©dictions correctes: {correct_predictions}/{total_predictions}")
    
    # Affichage avec barre verte
    barre_accuracy = create_progress_bar(accuracy_percentage, width=25)
    print(f"   Accuracy globale: {barre_accuracy}")
    
    # Ã‰valuation du niveau avec emoji
    if accuracy_percentage >= 95:
        niveau = "ğŸŸ¢ EXCELLENT"
        commentaire = "Le modÃ¨le est trÃ¨s performant !"
    elif accuracy_percentage >= 85:
        niveau = "ğŸŸ¡ BON"
        commentaire = "Le modÃ¨le fonctionne bien avec quelques amÃ©liorations possibles."
    elif accuracy_percentage >= 70:
        niveau = "ğŸŸ  ACCEPTABLE"
        commentaire = "Le modÃ¨le est fonctionnel mais nÃ©cessite des amÃ©liorations."
    else:
        niveau = "ğŸ”´ FAIBLE"
        commentaire = "Le modÃ¨le nÃ©cessite des amÃ©liorations importantes."
    
    print(f"   Niveau: {niveau}")
    print(f"   Ã‰valuation: {commentaire}")
    
    # Analyser les erreurs
    errors = []
    for i, (pred, true) in enumerate(zip(predicted_labels, expected_labels)):
        if pred != true:
            errors.append({
                'input': test_inputs[i],
                'expected': true,
                'predicted': pred
            })
    
    if errors:
        print(f"\nâŒ ERREURS DÃ‰TECTÃ‰ES ({len(errors)}):")
        print("-" * 60)
        for error in errors:
            print(f"   Input: '{error['input']}'")
            print(f"   Attendu: {error['expected']}")
            print(f"   PrÃ©dit: {error['predicted']}")
            print()
    else:
        print("\nâœ… AUCUNE ERREUR DÃ‰TECTÃ‰E!")
    
    # Rapport dÃ©taillÃ© par classe avec barres
    print("\nğŸ“Š RAPPORT DÃ‰TAILLÃ‰ PAR INTENTION:")
    print("-" * 80)
    
    # Compter les prÃ©dictions par classe
    unique_labels = set(expected_labels + predicted_labels)
    
    for label in sorted(unique_labels, key=lambda x: (x is None, x)):
        if label is None:
            label_str = "None (pas d'intention)"
        else:
            label_str = label
            
        expected_count = expected_labels.count(label)
        predicted_count = predicted_labels.count(label)
        correct_count = sum(1 for p, e in zip(predicted_labels, expected_labels) 
                          if p == label and e == label)
        
        if expected_count > 0:
            precision = (correct_count / expected_count) * 100 if expected_count > 0 else 0
            barre_precision = create_progress_bar(precision, width=15)
            print(f"   {label_str:25} | Attendu: {expected_count:2d} | Correct: {correct_count:2d}")
            print(f"   {'':25} | PrÃ©cision: {barre_precision}")
            print()
    
    return accuracy, errors

def test_edge_cases():
    """
    Teste des cas limites pour valider la robustesse
    """
    print("\nğŸ” TEST DES CAS LIMITES:")
    print("-" * 40)
    
    edge_cases = [
        "BONJOUR",  # Majuscules
        "bonjour!",  # Ponctuation
        "   salut   ",  # Espaces
        "cong congÃ© congÃ©s",  # Mots multiples
        "je veux voir mes congÃ©s historique",  # Intentions multiples
        "blabla congÃ© blabla",  # Mot clÃ© noyÃ©
    ]
    
    for case in edge_cases:
        prediction = detect_intent(case)
        print(f"   '{case}' -> {prediction}")

def main():
    """
    Fonction principale
    """
    print("ğŸ¤– TEST D'ACCURACY DU MODÃˆLE DE DÃ‰TECTION D'INTENTION")
    print("=" * 80)
    
    # Test principal
    accuracy, errors = test_model_accuracy()
    
    # Tests de cas limites
    test_edge_cases()
    
    # Recommandations avec barres
    print(f"\nğŸ’¡ RECOMMANDATIONS:")
    print("-" * 50)
    
    accuracy_percentage = accuracy * 100
    
    if accuracy >= 0.95:
        print("   âœ… Excellent! Le modÃ¨le a une trÃ¨s bonne accuracy.")
        barre_recommandation = create_progress_bar(100, width=20)
        print(f"   Statut du modÃ¨le: {barre_recommandation}")
    elif accuracy >= 0.85:
        print("   âœ… Bon! Le modÃ¨le fonctionne bien.")
        print("   ğŸ’¡ ConsidÃ©rez d'ajouter plus d'exemples pour les classes avec erreurs.")
        barre_recommandation = create_progress_bar(85, width=20)
        print(f"   Statut du modÃ¨le: {barre_recommandation}")
    elif accuracy >= 0.70:
        print("   âš ï¸  Acceptable mais peut Ãªtre amÃ©liorÃ©.")
        print("   ğŸ’¡ Ajoutez plus de mots-clÃ©s ou d'exemples d'entraÃ®nement.")
        barre_recommandation = create_progress_bar(70, width=20)
        print(f"   Statut du modÃ¨le: {barre_recommandation}")
    else:
        print("   âŒ Le modÃ¨le nÃ©cessite des amÃ©liorations importantes.")
        print("   ğŸ’¡ Revisitez la logique de dÃ©tection d'intention.")
        barre_recommandation = create_progress_bar(50, width=20)
        print(f"   Statut du modÃ¨le: {barre_recommandation}")
    
    if len(errors) > 0:
        error_rate = (len(errors) / len(TEST_DATA)) * 100
        barre_erreurs = create_progress_bar(100 - error_rate, width=15)
        print(f"   ğŸ“ Taux de rÃ©ussite: {barre_erreurs}")
        print(f"   ğŸ“ Analysez les {len(errors)} erreurs pour amÃ©liorer le modÃ¨le.")
    
    print(f"\nğŸ“‹ SUMMARY:")
    print(f"   Total d'exemples testÃ©s: {len(TEST_DATA)}")
    
    # Summary avec barre finale
    barre_finale = create_progress_bar(accuracy_percentage, width=30)
    print(f"   Accuracy finale: {barre_finale}")
    print(f"   Nombre d'erreurs: {len(errors)}")

if __name__ == "__main__":
    main()
